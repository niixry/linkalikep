#бот без токена

!pip install pyTelegramBotAPI
import telebot
import requests
from bs4 import BeautifulSoup
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

TOKEN = 'не'
bot = telebot.TeleBot(TOKEN)

model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

user_requests = {}

def parse_habr_articles(topic, limit=1000):
    base_url = 'https://habr.com/'
    response = requests.get(base_url)
    if response.status_code != 200:
        print(f"Ошибка загрузки {base_url}")
        return []
    soup = BeautifulSoup(response.text, 'html.parser')
    articles = []

    for link in soup.find_all('a', href=True):
        href = link['href']
        if href.startswith('/en/articles/') and href not in articles and not href.endswith('/comments/'):
          articles.append(base_url + href)

        elif href.startswith('/en/companies/') and href not in articles and not href.endswith('/comments/'):
          articles.append(base_url + href)

        if len(articles) >= limit:
            break
    info = []
    for art in articles:
      response = requests.get(art)
      if response.status_code != 200:
          print(f"Ошибка загрузки {art}")
          return None
      soup = BeautifulSoup(response.text, 'html.parser')
      title = soup.find('h1').text.strip() if soup.find('h1') else 'Нет заголовка'
      text = ' '.join([p.text for p in soup.select('p')])
      info.append((title, text, art))
    return info

def parse_wikipedia_articles(topic, limit=1000):
    url = "https://ru.wikipedia.org/w/api.php"
    params = {
        "action": "query",
        "format": "json",
        "list": "search",
        "srsearch": topic,
        "srlimit": limit
    }
    response = requests.get(url, params=params)
    results = response.json().get('query', {}).get('search', [])

    articles = []
    for result in results:
        page_url = f"https://ru.wikipedia.org/wiki/{result['title'].replace(' ', '_')}"
        page_response = requests.get(page_url)
        page_soup = BeautifulSoup(page_response.text, 'html.parser')
        text = ' '.join([p.text for p in page_soup.select('p')])
        articles.append((result['title'], text, page_url))

    return articles

def find_similar_articles(articles, target_title, target_text):
    all_articles = [(target_title, target_text, "введенная ссылка")] + articles
    titles, texts, urls = zip(*all_articles)

    embeddings = model.encode(texts)
    similarity_matrix = cosine_similarity(embeddings)

    for i, title in enumerate(titles):
        if title == target_title:
            similar_indices = np.argsort(similarity_matrix[i])[::-1][1:4]
            return [(titles[j], urls[j]) for j in similar_indices if j < len(titles)]
    return []

@bot.message_handler(commands=['lookforlink'])
def look_for_link(message):
    bot.send_message(message.chat.id, "Отправьте ссылку на статью с википедии или хабра")
    user_requests[message.chat.id] = "lookforlink"

@bot.message_handler(commands=['lookfortheme'])
def look_for_theme(message):
    bot.send_message(message.chat.id, "Введите тему для поиска")
    user_requests[message.chat.id] = "lookfortheme"

@bot.message_handler(func=lambda message: message.chat.id in user_requests)
def process_user_input(message):
    user_id = message.chat.id
    command = user_requests.pop(user_id)

    if command == "lookforlink":
        url = message.text.strip()
        if not (url.startswith("https://ru.wikipedia.org/wiki/") or url.startswith("https://habr.com/")):
            bot.send_message(user_id, "ало норм ссылку отправь")
            return

        response = requests.get(url)
        if response.status_code != 200:
            bot.send_message(user_id, "Ошибка загрузки ссылки, перепроверьте")
            return

        soup = BeautifulSoup(response.text, 'html.parser')
        title = soup.find('h1').text.strip() if soup.find('h1') else 'Нет заголовка'
        text = ' '.join([p.text.strip() for p in soup.select('p')])

        all_articles = parse_habr_articles(title) + parse_wikipedia_articles(title)
        similar_articles = find_similar_articles(all_articles, title, text)

        response_text = f"Статья: {title} ({url})\nПохожие статьи:\n"
        response_text += "\n".join([f"  - {t} ({u})" for t, u in similar_articles]) if similar_articles else "Нет похожих статей"
        bot.send_message(user_id, response_text)

    elif command == "lookfortheme":
        topic = message.text.strip()
        bot.send_message(user_id, f"Ищу статьи по теме: {topic}...")

        all_articles = parse_habr_articles(title) + parse_wikipedia_articles(title)

        if not all_articles:
            bot.send_message(user_id, "Не найдено статей по данной теме")
            return

        titles, _, urls = zip(*all_articles)
        response_text = "Найденные статьи:\n"
        response_text += "\n".join([f"  - {t} ({u})" for t, u in zip(titles, urls)])

        bot.send_message(user_id, response_text)

if __name__ == "__main__":
    print("бот запущен")
    bot.polling(none_stop=True)
